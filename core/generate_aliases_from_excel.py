#!/usr/bin/env python3
"""
ä»æœ¬åœ° Excel æ–‡ä»¶ç”Ÿæˆåˆ«å CSV è¡¨æ ¼
ç”¨äºè°ƒè¯•å’Œå‡†å¤‡åˆ«åæ•°æ®
"""

import sys
import argparse
from pathlib import Path
from typing import Set, List, Tuple
import pandas as pd
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.cleaning_rules import CleaningRules


def extract_people_from_excel(excel_path: str, config_path: str = "config/config.json") -> List[Tuple[str, int]]:
    """
    ä» Excel æ–‡ä»¶ä¸­æå–æ‰€æœ‰äººå
    
    Args:
        excel_path: Excel æ–‡ä»¶è·¯å¾„
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        äººååˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(name, count), ...]ï¼ŒæŒ‰å‡ºç°æ¬¡æ•°æ’åº
    """
    import json
    
    # è¯»å–é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # è¯»å– Excel æ–‡ä»¶
    print(f"ğŸ“– è¯»å– Excel æ–‡ä»¶: {excel_path}")
    df = pd.read_excel(excel_path)
    print(f"âœ… æˆåŠŸè¯»å– {len(df)} è¡Œæ•°æ®")
    print(f"ğŸ“Š åˆ—å: {list(df.columns)}")
    print()
    
    # è·å–äººåç›¸å…³çš„åˆ—ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
    people_columns = [
        'preacher',
        'worship_lead',
        'worship_team_1',
        'worship_team_2',
        'pianist',
        'audio',
        'video',
        'propresenter_play',
        'propresenter_update',
        'assistant'
    ]
    
    # è·å–ä¸­æ–‡åˆ—å
    column_mapping = config['columns']
    chinese_people_columns = [column_mapping.get(col) for col in people_columns if col in column_mapping]
    
    print(f"ğŸ” æ£€æŸ¥ä»¥ä¸‹äººååˆ—: {chinese_people_columns}")
    print()
    
    # åˆå§‹åŒ–æ¸…æ´—è§„åˆ™
    cleaning_rules = CleaningRules(config['cleaning_rules'])
    
    # æ”¶é›†æ‰€æœ‰äººå
    people_counter = Counter()
    
    for col in chinese_people_columns:
        if col in df.columns:
            print(f"ğŸ“‹ å¤„ç†åˆ—: {col}")
            for value in df[col]:
                # æ¸…ç†äººå
                cleaned = cleaning_rules.clean_name(value)
                if cleaned:
                    people_counter[cleaned] += 1
                    print(f"  - {cleaned}")
    
    print()
    print(f"âœ… å…±æ‰¾åˆ° {len(people_counter)} ä¸ªå”¯ä¸€äººå")
    print()
    
    # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
    sorted_people = sorted(people_counter.items(), key=lambda x: x[1], reverse=True)
    
    return sorted_people


def generate_alias_csv(
    people_list: List[Tuple[str, int]],
    output_path: str,
    include_count: bool = True
):
    """
    ç”Ÿæˆåˆ«å CSV æ–‡ä»¶
    
    Args:
        people_list: äººååˆ—è¡¨ [(name, count), ...]
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        include_count: æ˜¯å¦åŒ…å«å‡ºç°æ¬¡æ•°åˆ—
    """
    print(f"ğŸ“ ç”Ÿæˆåˆ«å CSV: {output_path}")
    
    # å‡†å¤‡æ•°æ®
    rows = []
    for name, count in people_list:
        # ç”Ÿæˆé»˜è®¤çš„ person_idï¼ˆä½¿ç”¨æ‹¼éŸ³æˆ–ç®€å•è½¬æ¢ï¼‰
        # è¿™é‡Œç”¨ç®€å•çš„è§„åˆ™ï¼Œç”¨æˆ·å¯ä»¥åç»­æ‰‹åŠ¨è°ƒæ•´
        person_id = f"person_{name.lower().replace(' ', '_')}"
        
        row = {
            'alias': name,
            'person_id': person_id,
            'display_name': name
        }
        
        if include_count:
            row['count'] = count
        
        rows.append(row)
    
    # åˆ›å»º DataFrame
    df = pd.DataFrame(rows)
    
    # ä¿å­˜ä¸º CSV
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"âœ… å·²ç”Ÿæˆ {len(rows)} æ¡åˆ«åè®°å½•")
    print()
    print("ğŸ“‹ å‰ 10 æ¡è®°å½•é¢„è§ˆ:")
    print(df.head(10).to_string(index=False))
    print()
    
    if include_count:
        print("ğŸ“Š å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰ 10 ä½:")
        top_10 = df.nlargest(10, 'count')
        for _, row in top_10.iterrows():
            print(f"  {row['display_name']:20s} - {row['count']:2d} æ¬¡")
        print()
    
    print("ğŸ’¡ æç¤º:")
    print("  1. è¯·æ£€æŸ¥å¹¶æ‰‹åŠ¨ç¼–è¾‘ CSV æ–‡ä»¶")
    print("  2. åˆå¹¶åŒä¸€äººçš„ä¸åŒå†™æ³•ï¼ˆå¦‚ï¼šå¼ ç‰§å¸ˆã€Pastor Zhangã€å¼ ï¼‰")
    print("  3. å°†å®ƒä»¬çš„ person_id æ”¹ä¸ºç›¸åŒå€¼")
    print("  4. è®¾ç½®ç»Ÿä¸€çš„ display_name")
    print()


def preview_data(excel_path: str, n_rows: int = 5):
    """
    é¢„è§ˆ Excel æ–‡ä»¶çš„å‰å‡ è¡Œæ•°æ®
    
    Args:
        excel_path: Excel æ–‡ä»¶è·¯å¾„
        n_rows: é¢„è§ˆè¡Œæ•°
    """
    print(f"ğŸ‘€ é¢„è§ˆ Excel æ–‡ä»¶: {excel_path}")
    print()
    
    df = pd.read_excel(excel_path)
    
    print(f"ğŸ“Š æ€»è¡Œæ•°: {len(df)}")
    print(f"ğŸ“Š æ€»åˆ—æ•°: {len(df.columns)}")
    print()
    
    print(f"ğŸ“‹ åˆ—ååˆ—è¡¨:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i:2d}. {col}")
    print()
    
    print(f"ğŸ“– å‰ {n_rows} è¡Œæ•°æ®:")
    print(df.head(n_rows).to_string())
    print()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä» Excel æ–‡ä»¶ç”Ÿæˆåˆ«å CSV è¡¨æ ¼',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # é¢„è§ˆ Excel æ•°æ®
  python scripts/generate_aliases_from_excel.py --excel tests/data.xlsx --preview
  
  # ç”Ÿæˆåˆ«å CSVï¼ˆåŒ…å«å‡ºç°æ¬¡æ•°ï¼‰
  python scripts/generate_aliases_from_excel.py --excel tests/data.xlsx -o tests/aliases.csv
  
  # ç”Ÿæˆåˆ«å CSVï¼ˆä¸åŒ…å«å‡ºç°æ¬¡æ•°ï¼Œç”¨äºä¸Šä¼ åˆ° Google Sheetsï¼‰
  python scripts/generate_aliases_from_excel.py --excel tests/data.xlsx -o tests/aliases.csv --no-count
        """
    )
    
    parser.add_argument(
        '--excel',
        type=str,
        required=True,
        help='Excel æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '-o', '--output',
        type=str,
        default='tests/generated_aliases.csv',
        help='è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: tests/generated_aliases.csvï¼‰'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config/config.json',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config/config.jsonï¼‰'
    )
    parser.add_argument(
        '--preview',
        action='store_true',
        help='ä»…é¢„è§ˆ Excel æ•°æ®ï¼Œä¸ç”Ÿæˆ CSV'
    )
    parser.add_argument(
        '--no-count',
        action='store_true',
        help='ä¸åœ¨ CSV ä¸­åŒ…å«å‡ºç°æ¬¡æ•°åˆ—ï¼ˆç”¨äºä¸Šä¼ åˆ° Google Sheetsï¼‰'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.excel).exists():
        print(f"âŒ é”™è¯¯: Excel æ–‡ä»¶ä¸å­˜åœ¨: {args.excel}")
        sys.exit(1)
    
    # é¢„è§ˆæ¨¡å¼
    if args.preview:
        preview_data(args.excel)
        return
    
    # æå–äººå
    try:
        people_list = extract_people_from_excel(args.excel, args.config)
    except Exception as e:
        print(f"âŒ é”™è¯¯: æå–äººåå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    if not people_list:
        print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•äººå")
        sys.exit(0)
    
    # ç”Ÿæˆ CSV
    try:
        generate_alias_csv(
            people_list,
            args.output,
            include_count=not args.no_count
        )
    except Exception as e:
        print(f"âŒ é”™è¯¯: ç”Ÿæˆ CSV å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print(f"ğŸ‰ å®Œæˆï¼åˆ«å CSV å·²ä¿å­˜åˆ°: {args.output}")
    print()
    print("ğŸ“ ä¸‹ä¸€æ­¥:")
    print(f"  1. ç¼–è¾‘ {args.output}ï¼Œåˆå¹¶åŒä¸€äººçš„ä¸åŒå†™æ³•")
    print("  2. æµ‹è¯•æœ¬åœ°æ¸…æ´—: python scripts/debug_clean_local.py")
    print("  3. ä¸Šä¼ åˆ° Google Sheetsï¼ˆä½¿ç”¨ --no-count é€‰é¡¹é‡æ–°ç”Ÿæˆï¼‰")
    print()


if __name__ == '__main__':
    main()

